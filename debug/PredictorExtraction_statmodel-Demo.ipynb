{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.insert(0, '/home/rnshishir/deepmed/CPRD_Cut22/')\n",
    "import shutil\n",
    "from utils.yaml_act import yaml_load\n",
    "from utils.arg_parse import arg_paser\n",
    "from CPRD.config.spark import spark_init, read_parquet\n",
    "import pyspark.sql.functions as F\n",
    "from CPRD.functions import tables, merge\n",
    "from CPRD.functions import merge\n",
    "from CPRD.functions.merge import *\n",
    "\n",
    "from utils.utils import save_obj\n",
    "from CPRD.functions.MedicalDictionary import * \n",
    "from CPRD.functions.Prediction import * \n",
    "from CPRD.functions.cohort_select import * \n",
    "from CPRD.functions.SurvPrediction import * \n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vocabCreate(CountsICD, num):\n",
    "    dic={}\n",
    "    dic['token2idx']={}\n",
    "    dic['idx2token']={}\n",
    "    dic['token2idx']['MASK']=4\n",
    "    dic['token2idx']['CLS']=3\n",
    "    dic['token2idx']['SEP']=2\n",
    "    dic['token2idx']['UNK']=1\n",
    "    dic['token2idx']['PAD']=0\n",
    "    dic['idx2token'][4]='MASK'\n",
    "    dic['idx2token'][3]='CLS'\n",
    "    dic['idx2token'][2]='SEP'\n",
    "    dic['idx2token'][1]='UNK'\n",
    "    dic['idx2token'][0]='PAD'\n",
    "    i=5\n",
    "    for x in CountsICD:\n",
    "        if CountsICD[x]>num:\n",
    "            dic['token2idx'][x]=i\n",
    "            dic['idx2token'][i]=x\n",
    "            i=i+1\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rnshishir/deepmed/CPRD_Cut22/utils/yaml_act.py:6: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  cfg = yaml.load(ymlfile)\n"
     ]
    }
   ],
   "source": [
    "args = dotdict({'params': '/home/rnshishir/deepmed/CPRD_Cut22/config/config.yaml'})\n",
    "params = yaml_load(args.params)\n",
    "spark_params = params['pyspark']\n",
    "spark = spark_init(spark_params)\n",
    "file = params['file_path']\n",
    "data_params = params['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'medication.main',\n",
       " 'pyspark': {'temp': '/home/rnshishir/sparkNewT',\n",
       "  'pyspark_env': '/home/rnshishir/anaconda3/envs/pyspark37/bin/python3.7'},\n",
       " 'file_path': {'clinical': '/home/workspace/datasets/cprd/cprd2021/*/*_Observation_*',\n",
       "  'patient': '/home/workspace/datasets/cprd/cprd2021/*/*_Patient_*',\n",
       "  'problem': '/home/workspace/datasets/cprd/cprd2021/*/*_Problem_*',\n",
       "  'therapy': '/home/workspace/datasets/cprd/cprd2021/*/*_DrugIssue_*',\n",
       "  'referral': '/home/workspace/datasets/cprd/cprd2021/*/*_Referral_*',\n",
       "  'practice': '/home/workspace/datasets/cprd/cprd2021/*/*_Practice_*',\n",
       "  'consultation': '/home/workspace/datasets/cprd/cprd2021/*/*_Consultation_*',\n",
       "  'staff': '/home/workspace/datasets/cprd/cprd2021/*/*_Staff*',\n",
       "  'diagnosis_hes': '/home/workspace/datasets/cprd/cprd2021/linkage/20_095_Results/*/Aurum_linked/Final/hes_diagnosis_hosp_20_095_DM.txt',\n",
       "  'proc_hes': '/home/workspace/datasets/cprd/cprd2021/linkage/20_095_Results/*/Aurum_linked/Final/hes_procedures_epi_20_095_DM.txt',\n",
       "  'op_hes': '/home/workspace/datasets/cprd/cprd2021/linkage/20_095_Results/*/Aurum_linked/Final/hesop_clinical_20_095_DM.txt',\n",
       "  'death': '/home/workspace/datasets/cprd/cprd2021/linkage/20_095_Results/*/Aurum_linked/Final/death_patient_20_095_DM.txt',\n",
       "  'eligible': '/home/workspace/datasets/cprd/cprd2021/linkage_eligibility_Set21/linkage_eligibility*',\n",
       "  'med2read': '/home/workspace/datasets/cprd/cprd2021/202102_lookups/202102_EMISMedicalDictionary.txt',\n",
       "  'med2sno': '/home/workspace/datasets/cprd/cprd2021/202102_lookups/202102_EMISMedicalDictionary.txt',\n",
       "  'medicalDict': '/home/shared/shishir/AurumOut/Dicts/MedicalDictionary/CompiledDict/',\n",
       "  'uptodateDict': '/home/workspace/datasets/cprd/cprd2021/linkage/20_095_Results/Documentation/*/linkage_coverage_dictv.pkl',\n",
       "  'prod2bnf': '/home/workspace/datasets/cprd/cprd2021/202102_lookups/202102_EMISProductDictionary.txt',\n",
       "  'prod2bnf_vtm': '/home/shared/shishir/AurumOut/Dicts/meds_medcount_full.parquet',\n",
       "  'read2icd': '/home/workspace/datasets/cprd/cuts/02_cprd2015/3_Lookups/final_mapping.csv',\n",
       "  'sno2icd': '/home/shared/shishir/AurumOut/Dicts/snomed2icd.parquet',\n",
       "  'imd': '/home/workspace/datasets/cprd/cprd2021/linkage/20_095_Results/*/Aurum_linked/Final/patient_imd2015_20_095.txt',\n",
       "  'PhenoMaps': '/home/shared/shishir/AurumOut/Dicts/compiled_MD_23Nov2023',\n",
       "  'diag2keep': '/home/shared/shishir/AurumOut/Dicts/diagcodes2keep.parquet',\n",
       "  'hes_patient': '/home/workspace/datasets/cprd/cprd2021/linkage/20_095_Results/*/Aurum_linked/Final/hes_patient_20_095_DM.txt'},\n",
       " 'params': {'bnf_mapping': True, 'time_range': [1985, 2022]},\n",
       " 'save_file': 'medication.parquet'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params have each of the individual files for data processing and other things like location of medical dict etc\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictor extraction...\n",
    "### maybe predictors for the (part of the) qrisk3 model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDiag = read_parquet(spark.sqlContext, '/home/shared/shishir/AurumOut/rawDat/diagGP_med2sno2icd_HESAPC_praclinkage_1985_2021.parquet')\n",
    "meds = read_parquet(spark.sqlContext, '/home/shared/shishir/AurumOut/rawDat/medications_1985_2022_bnfvtm.parquet')\n",
    "proc = read_parquet(spark.sqlContext, '/home/shared/shishir/AurumOut/rawDat/proc_HES_1985_2021_allpats.parquet').withColumnRenamed('OPCS','code')\n",
    "\n",
    "proc = proc.withColumn('code', F.concat(F.lit(\"PROC_\"), F.col('code'))).select('patid','eventdate','code')\n",
    "\n",
    "allDiag = allDiag.select('patid','eventdate','ICD').withColumnRenamed('ICD','code')\n",
    "meds = meds.select('patid','eventdate','code')\n",
    "fullcodes = allDiag.union(meds).union(proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample cohort with 100 patients or so\n",
    "cohort = read_parquet(spark.sqlContext,'predextract_cohort_demo.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CPRD.functions.predictor_extractor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = PredictorExtractorBase()\n",
    "md = MedicalDictionaryRiskPrediction(file, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cont and categorical variable extraction\n",
    "### variable name is show in each cell\n",
    "#### Lookback before baseline is span_before_baseline_month, and what you want is type: last, mean, std, etc... examples are self explanatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bmi extract\n",
    "bmi = read_parquet(spark.sqlContext ,'/home/shared/shishir/AurumOut/rawDat/bmi_1985_2021.parquet')\n",
    "bmi = predictor.predictor_extract(bmi, cohort, 'BMI',colname = 'bmi', col_baseline='study_entry', span_before_baseline_month=36, type='last')\n",
    "cohort = cohort.join(bmi, 'patid', 'left')\n",
    "\n",
    "\n",
    "\n",
    "cohort.write.parquet('/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv1'+\"test.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoking status extract\n",
    "cohort = read_parquet(spark.sqlContext,'/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv1'+\"test.parquet\")\n",
    "print(cohort.count())\n",
    "smoke = read_parquet(spark.sqlContext ,'/home/shared/shishir/AurumOut/rawDat/smoklevel_1985_2021.parquet')\n",
    "smoke = predictor.predictor_extract(smoke, cohort, 'smoke',colname = 'smoke' , col_baseline='study_entry', span_before_baseline_month=1000,type='last')\n",
    "cohort = cohort.join(smoke, 'patid', 'left')\n",
    "\n",
    "cohort.write.parquet('/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv2'+\"test.parquet\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tchdl extract\n",
    "cohort = read_parquet(spark.sqlContext,'/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv2'+\"test.parquet\")\n",
    "\n",
    "tchdl = read_parquet(spark.sqlContext ,'/home/shared/shishir/AurumOut/rawDat/tchdl_rat_1985_2021.parquet')\n",
    "# tchdl = retrieve_smoking_status(file, spark, duration=(1985, 2021))\n",
    "tchdl = predictor.predictor_extract(tchdl, cohort, 'tchdl_rat',colname = 'tchdl' , col_baseline='study_entry', span_before_baseline_month=36,type='mean')\n",
    "cohort = cohort.join(tchdl, 'patid', 'left')\n",
    "\n",
    "cohort.write.parquet('/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv3'+\"test.parquet\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bp extract\n",
    "cohort = read_parquet(spark.sqlContext,'/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv3'+\"test.parquet\")\n",
    "print(cohort.count())\n",
    "\n",
    "bp = read_parquet(spark.sqlContext ,'/home/shared/shishir/AurumOut/rawDat/AllBP_praclinkage_1985_2021.parquet')\n",
    "bp = predictor.predictor_extract(bp, cohort, 'systolic',colname= 'systolic', col_baseline='study_entry', span_before_baseline_month=1000,type='last')\n",
    "cohort = cohort.join(bp, 'patid', 'left')\n",
    "\n",
    "cohort.write.parquet('/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv4'+\"test.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interesting one :) - this is systolic blood pressure Standard Deviation extraction, yes, you got that right, i have also coded this!\n",
    "cohort = read_parquet(spark.sqlContext,'/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv4'+\"test.parquet\")\n",
    "print(cohort.count())\n",
    "\n",
    "bp = read_parquet(spark.sqlContext ,'/home/shared/shishir/AurumOut/rawDat/AllBP_praclinkage_1985_2021.parquet')\n",
    "bp = predictor.predictor_extract(bp, cohort, 'systolic',colname= 'sysvar', col_baseline='study_entry', span_before_baseline_month=36,type='std')\n",
    "cohort = cohort.join(bp, 'patid', 'left')\n",
    "\n",
    "cohort.write.parquet('/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv5'+\"test.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = read_parquet(spark.sqlContext,'/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv5'+\"test.parquet\")\n",
    "cohort = pd.read_parquet('/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv5'+\"test.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease/medication/procedure at baseline variable extraction\n",
    "### variable name is show in each cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "['M0630', 'M0534', 'M0500', 'M0507', 'M0590', 'M0506', 'M0508', 'M0524', 'M0580', 'M0585', 'M0638', 'M0699', 'M0504', 'M0698', 'M0598', 'M0502', 'M0593', 'M0696', 'M0625', 'M0589', 'M0603', 'M0623', 'M080', 'M0588', 'M0522', 'M0595', 'M0689', 'M0803', 'M0607', 'M0510', 'M0530', 'M0631', 'M0686', 'M062', 'M0519', 'M05', 'M0601', 'M0501', 'M0634', 'M0639', 'M0521', 'M0694', 'M063', 'M058', 'M0606', 'M0809', 'M0685', 'M0636', 'M0528', 'M0691', 'M0532', 'M0695', 'M0806', 'M0802', 'M0801', 'M0539', 'M0514', 'M0628', 'M0692', 'M0687', 'M0527', 'M0596', 'M0682', 'M0513', 'M0520', 'M0525', 'M0526', 'M0633', 'M0533', 'M0684', 'M0581', 'M0690', 'M050', 'M0804', 'M059', 'M0516', 'M0517', 'M0591', 'M0594', 'M0509', 'M068', 'M0608', 'M053', 'M0627', 'M0584', 'M0523', 'M0537', 'M0583', 'M0609', 'M0624', 'M0503', 'M0535', 'M0688', 'M0518', 'M0531', 'M0592', 'M060', 'M0635', 'M0600', 'M0529', 'M0602', 'M0605', 'M0538', 'M0808', 'M0632', 'M0800', 'M0586', 'M0604', 'M0512', 'M052', 'M0511', 'M0597', 'M0680', 'M069', 'M0805', 'M0807', 'M0536', 'M0629', 'M0599', 'M0637', 'M0683', 'M0621', 'M0515', 'M0681', 'M0697', 'M051', 'M0582', 'M0693', 'M0626', 'M0587', 'M0505', 'J990', 'M0622', 'M0620', 'M06', '48361011', '6608781000006113', '309798015', '1779323014', '4809181000006117', '6802581000006114', '309789018', '309788014', '162231000006117', '297544012', '11903911000006111', '162041000006117', '485614018', '309805017', '6802661000006115', '297641010', '162131000006111', '359292012', '116082011', '7099641000006113', '3636551000006114', '309790010', '309792019', '2472447010', '755441000006119', '309800010', '309803012', '125937016', '309828016', '162301000006117', '123542016', '309791014', '95067016', '5721431000006114', '300221014', '312534011', '309787016', '168761000006118', '309816012', '889731000006111', '162081000006111', '2670341000006112', '16911000006114', '162051000006115', '162141000006118', '312520011', '3042571000006112', '309824019', '309827014', '168751000006115', '309802019', '309804018', '3732891000006112', '3636541000006112', '4809341000006114', '451461014', '162101000006115', '3042581000006110', '1778239014', '6608771000006110', '1786505011', '2842168015', '371261000000111', '309812014', '426510015', '149911000006117', '3428911000006119', '3636561000006111', '3428891000006116', '2653371000006113', '255925015', '424981000006114', '6608791000006111', '309794018', '311496011', '4809301000006112', '3428901000006117', '3709251000006117', '162191000006110', '162341000006115', '2839291014', '162111000006117', '4580651000006110', '1786545019', '312518013', '4809101000006114', '4809221000006114']\n"
     ]
    }
   ],
   "source": [
    "# generic... rheumaatoid arthritis\n",
    "cohort = read_parquet(spark.sqlContext,'/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv5'+\"test.parquet\")\n",
    "print(cohort.count())\n",
    "rheum = md.queryDisease(md.findItem('rheumatoid art'), merge= True)['rheumatoid arthritis']\n",
    "allcoderheum = list(rheum['ICD10']) + list(rheum['medcode'])\n",
    "print(allcoderheum)\n",
    "\n",
    "allDiag_preserve = split_combine_diag (spark , '/home/shared/shishir/AurumOut/rawDat/diagGP_med2sno2icd_HESAPC_praclinkage_1985_2021.parquet')\n",
    "\n",
    "rheum = predictor.predictor_check_exist(allcoderheum, allDiag_preserve, cohort, col='code', col_baseline='study_entry').withColumnRenamed('code', 'rheum')\n",
    "cohort = cohort.join(rheum, 'patid', 'left')\n",
    "cohort.write.parquet('/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv6'+\"test.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K766', 'I272', 'I270', 'G932', 'I119', 'I10', 'I12', 'I13', 'I158', 'I11', 'I152', 'P292', 'I15', 'I110', 'G932', 'I674', 'I159', 'I150', '5057801000006113', '3552511000006116', '741661000006118', '99047018', '76661000006110', '3117511000006117', '64282015', '443764015', '909441000006118', '3468501000006117', '523801000006119', '26091000000116', '4356081000006115', '2566081000006118', '264486018', '351361000000117', '76651000006113', '728671000006119', '76631000006118', '1780252014', '4775791000006113', '3117461000006115', '300870016', '299687010', '158241000006117', '3552501000006119', '3950631000006119', '99042012', '395751018', '3784371000006115', '3117411000006118', '151161000006115', '2193021000000110', '3296351000006114', '2193971000000110', '741701000006114', '1806071000006118', '350601000000116', '299680012', '19411000006110', '316848016', '3552521000006112', '76671000006115', '4775861000006110', '3768511000006114', '143003017', '90135019', '884121000006111', '1846961000006115', '504901000006118', '3891091000006118', '264471012', '5911761000006110', '299683014', '264485019', '300871017', '76681000006117', '299682016', '3117471000006110', '19421000006119', '262960017', '299665018', '3552531000006110', '2193031000000112', '741691000006114', '535591000000118', '395753015', '504821000006119', '76641000006111', '2159168015', '504911000006115', '8286321000006117', '3117501000006115', '299655012', '3117521000006113', '991731000006118', '113392018', '84112010', '299673010', '1806081000006115', '3852501000006115', '12496011', '5324931000006116', '12488221000006116', '887811000006117', '504781000006113', '3610811000006117', '530221000000112', '1131851000000118', '504811000006110', '504801000006112', '504791000006111', '299684015', '3610821000006113', '3135013', '789941000006117', '300869017', '2011000033113', '57989014', '3117431000006112', '93494011', '213081000006118', '80224019', '28411000033112', '64168014', '887831000006111', '1908721000006111', '47076011', '4634661000006118', '1780318013', '299676019', '110659019', '4634871000006112', '1846991000006111', '4634851000006119', '3117451000006117', '131046010', '109700019', '108730018', '3117481000006113', '530161000000111', '146259010', '299678018', '1823901000006112', '535651000000113', '1806141000006113', '3693711000006119', '8093016', '12488211000006112', '3468491000006113', '411508017', '2972251000006115', '4540441000006117', '351341000000118', '11998621000006116', '790121000006116', '299654011', '857151000006119', '3898601000006112', '299675015', '19431000006116', '2972301000006110', '264487010', '60444016', '299686018', '3117421000006114', '107545013', '884131000006114', '3119661000006114', '2645973019', '2478822013', '299681011', '3610801000006115', '64172013', '451424017', '264472017', '251674014', '84111015', '53452019', '4623221000006114', '299677011', '1529013', '1409014', '8286581000006114', '1846941000006119', '3642801000006112', '4634891000006113', '4775831000006118', '741681000006111', '299650019', 'na', '12487991000006112', '2566071000006116', '19451000006111', '728681000006116', '19441000006114', '28311000033116']\n",
      "portal hypertension not in dictionary\n",
      "secondary pulmonary hypertension not in dictionary\n",
      "primary pulmonary hypertension not in dictionary\n",
      "intracranial hypertension not in dictionary\n",
      "hypertension not in dictionary\n"
     ]
    }
   ],
   "source": [
    "# this is a tutorial for a complex disease extraction; traeated hypertension = not just hypertension, but ALSO treatment for hypertension\n",
    "\n",
    "cohort = read_parquet(spark.sqlContext,'/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv6'+\"test.parquet\")\n",
    "\n",
    "\n",
    "# get codees for hypertension\n",
    "hyptn = md.queryDisease(md.findItem('hypertension'), merge= True)['merged']\n",
    "allcodeHyperten = list(hyptn['ICD10']) + list(hyptn['medcode']) \n",
    "print(allcodeHyperten)\n",
    "\n",
    "# get codes for antihyp\n",
    "prodcodesAntiHyp  = md.queryMedication(md.findItem('hyperte'), merge= True)['merged']['prodcode']\n",
    "print(prodcodesAntiHyp)\n",
    "\n",
    "# load diag files and med files\n",
    "allDiag_preserve = split_combine_diag (spark , '/home/shared/shishir/AurumOut/rawDat/diagGP_med2sno2icd_HESAPC_praclinkage_1985_2021.parquet')\n",
    "meds = read_parquet(spark.sqlContext, '/home/shared/shishir/AurumOut/rawDat/medications_1985_2022_bnfvtm.parquet')[['patid','eventdate','prodcode']].withColumnRenamed('prodcode','code')\n",
    "\n",
    "\n",
    "# extract diag hyp\n",
    "Hyperten = predictor.predictor_check_exist(allcodeHyperten, allDiag_preserve, cohort, col='code', col_baseline='study_entry').withColumnRenamed('code', 'hyp')\n",
    "cohort = cohort.join(Hyperten, 'patid', 'left')\n",
    "\n",
    "# extract med antihyp\n",
    "antiHyperten = predictor.predictor_check_exist(prodcodesAntiHyp, meds, cohort, col='code', col_baseline='study_entry').withColumnRenamed('code', 'antihyp')\n",
    "cohort = cohort.join(antiHyperten, 'patid', 'left')\n",
    "\n",
    "# logic statement\n",
    "cohort = cohort.withColumn('treat_hyp',  F.when(((F.col(\"hyp\") ==1) &(F.col('antihyp')==1)) , 1)     .otherwise(0))\n",
    "cohort.write.parquet('/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv7'+\"test.parquet\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# antipsychotic extraction with CUSTOM codes!\n",
    "cohort = read_parquet(spark.sqlContext,'/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv7'+\"test.parquet\")\n",
    "# extract antispysch codes\n",
    "antipsychcodesdrug = pd.read_csv('antispych.txt').prodcodeid.values\n",
    "antipsychcodesdrug = [str(x) for x in antipsychcodesdrug]\n",
    "\n",
    "allcodeantipsych = antipsychcodesdrug\n",
    "print(allcodeantipsych)\n",
    "\n",
    "# load medications///\n",
    "meds = read_parquet(spark.sqlContext, '/home/shared/shishir/AurumOut/rawDat/medications_1985_2022_bnfvtm.parquet')[['patid','eventdate','prodcode']].withColumnRenamed('prodcode','code')\n",
    "\n",
    "antipsych = predictor.predictor_check_exist(allcodeantipsych, meds, cohort, col='code', col_baseline='study_entry').withColumnRenamed('code', 'antipsych')\n",
    "cohort = cohort.join(antipsych, 'patid', 'left')\n",
    "cohort.write.parquet('/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv8'+\"test.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fam history extraction\n",
    "cohort = read_parquet(spark.sqlContext,'/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv8'+\"CVD_survout_nostatin_withImd_withpracid_wValidstatus_1000GPsubset_cohort_25_84_2000_2020.parquet\")\n",
    "famhis = read_parquet(spark.sqlContext,'/home/shared/shishir/AurumOut/rawDat/famhistoryCHD_all.parquet')\n",
    "\n",
    "famhistorycodes = pd.read_csv('Familyhistorycoronaryheartdisease.csv')\n",
    "meddict = pd.read_table('/home/workspace/datasets/cprd/cprd2021/202102_lookups/202102_EMISMedicalDictionary.txt')\n",
    "famhistorycodes=famhistorycodes.Code.values\n",
    "famhistorygpcode = meddict[meddict.SnomedCTConceptId.isin(famhistorycodes)].MedCodeId.values\n",
    "famhistorygpcode = [str(x) for x in famhistorygpcode]\n",
    "allcodefamhistory = list(famhistorygpcode)\n",
    "\n",
    "\n",
    "\n",
    "# get fam history data\n",
    "famhis = read_parquet(spark.sqlContext,'/home/shared/shishir/AurumOut/rawDat/famhistoryCHD_all.parquet').withColumnRenamed('medcode','code')\n",
    "famhis= famhis.select('patid','eventdate','code')\n",
    "print(allcodefamhistory)\n",
    "\n",
    "# extarct chd fam history particularly...\n",
    "famhistory = predictor.predictor_check_exist(allcodefamhistory, famhis, cohort, col='code', col_baseline='enddate').withColumnRenamed('code', 'famhistory_chd')\n",
    "cohort = cohort.join(famhistory, 'patid', 'left')\n",
    "cohort.write.parquet('/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv9'+\"test.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMD and Ethnicity extraction!!\n",
    "\n",
    "cohort = read_parquet(spark.sqlContext,'/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv9'+\"CVD_survout_nostatin_withImd_withpracid_wValidstatus_1000GPsubset_cohort_25_84_2000_2020.parquet\")\n",
    "\n",
    "imd = read_parquet(spark.sqlContext,'/home/shared/shishir/AurumOut/rawDat/imd_allPats.parquet')\n",
    "eth = read_parquet(spark.sqlContext,'/home/shared/shishir/AurumOut/rawDat/raw_eth_linkedpat.parquet')\n",
    "\n",
    "cohort = cohort.join(eth,'patid','left')\n",
    "cohort = cohort.join(imd , 'patid','left')\n",
    "cohort.write.parquet('/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv10'+\"CVD_survout_nostatin_withImd_withpracid_wValidstatus_1000GPsubset_cohort_25_84_2000_2020.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = pd.read_parquet('/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv10'+\"CVD_survout_nostatin_withImd_withpracid_wValidstatus_1000GPsubset_cohort_25_84_2000_2020.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in [ 'rheum', 'hyp', 'antihyp', 'treat_hyp',  'antipsych', 'famhistory_chd',\n",
    "       ]:\n",
    "    print(x, cohort[x].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-BEHRT/BEHRT/TRisk etc data extraction \n",
    "### also option to make unique per N months (i.e., delete duplicate rec in a given N months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDiag = read_parquet(spark.sqlContext, '/home/shared/shishir/AurumOut/rawDat/diagGP_med2sno2icd_HESAPC_praclinkage_1985_2021.parquet')\n",
    "meds = read_parquet(spark.sqlContext, '/home/shared/shishir/AurumOut/rawDat/medications_1985_2022_bnfvtm.parquet')\n",
    "proc = read_parquet(spark.sqlContext, '/home/shared/shishir/AurumOut/rawDat/proc_HES_1985_2021_allpats.parquet').withColumnRenamed('OPCS','code')\n",
    "\n",
    "proc = proc.withColumn('code', F.concat(F.lit(\"PROC_\"), F.col('code'))).select('patid','eventdate','code')\n",
    "\n",
    "allDiag = allDiag.select('patid','eventdate','ICD').withColumnRenamed('ICD','code')\n",
    "meds = meds.select('patid','eventdate','code')\n",
    "fullcodes = allDiag.union(meds).union(proc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['patid',\n",
       " 'gender',\n",
       " 'dob',\n",
       " 'study_entry',\n",
       " 'startdate',\n",
       " 'enddate',\n",
       " 'exp_label',\n",
       " 'eventdate',\n",
       " 'label',\n",
       " 'time2event']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cohort = read_parquet(spark.sqlContext, 'test9_40m.parquet')\n",
    "\n",
    "cohort = cohort[['patid',\n",
    " 'gender',\n",
    " 'dob',\n",
    " 'study_entry',\n",
    " 'startdate',\n",
    " 'enddate',\n",
    " 'exp_label',\n",
    " 'label',\n",
    " 'time2event']]\n",
    "\n",
    "extractorBEHRT = BEHRTextraction()\n",
    "dataout = extractorBEHRT.format_behrt(fullcodes, cohort, col_entry = 'study_entry', unique_in_months=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataout.write.parquet('test9_40m__BEHRTbasedout.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataout = pd.read_parquet('test9_40m__BEHRTbasedout.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# custom extraction extra set of codes examples..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR CUSTOM EXTRACTION.... rheumaatoid arthritis\n",
    "cohort = read_parquet(spark.sqlContext,'/home/shared/shishir/AurumOut/CVDPred/'+'statsmodel_prepv5'+\"CVD_survout_nostatin_withImd_withpracid_wValidstatus_1000GPsubset_cohort_25_84_2000_2020.parquet\")\n",
    "\n",
    "rheumcodes = pd.read_csv('RheumatoidArthritis.csv')\n",
    "meddict = pd.read_table('/home/workspace/datasets/cprd/cprd2021/202102_lookups/202102_EMISMedicalDictionary.txt')\n",
    "rheumcodes=rheumcodes.Code.values\n",
    "rheumgpcode = meddict[meddict.SnomedCTConceptId.isin(rheumcodes)].MedCodeId.values\n",
    "rheumgpcode = [str(x) for x in rheumgpcode]\n",
    "rheumcodeicd10 = pd.read_csv('Rheumatoidarthritis(ICD10).csv')\n",
    "rheumcodeicd10 = rheumcodeicd10.Code.values\n",
    "\n",
    "allcoderheum = list(rheumcodeicd10) + list(rheumgpcode)\n",
    "print(allcoderheum)\n",
    "allDiag = read_parquet(spark.sqlContext, '/home/shared/shishir/AurumOut/rawDat/diagGP_med2sno2icd_HESAPC_praclinkage_1985_2021.parquet')\n",
    "GPdiags = allDiag[allDiag.source=='CPRD']\n",
    "GPdiags = GPdiags.select(['patid' , 'eventdate', 'medcode','source']).withColumnRenamed('medcode', 'code')\n",
    "HESdiags = allDiag[allDiag.source=='HES']\n",
    "HESdiags = HESdiags.select(['patid' , 'eventdate', 'ICD', 'source']).withColumnRenamed('ICD', 'code')\n",
    "allDiag_preserve= GPdiags.union(HESdiags).select('patid','eventdate','code')\n",
    "\n",
    "rheum = predictor.predictor_check_exist(allcoderheum, allDiag_preserve, cohort, col='code', col_baseline='study_entry').withColumnRenamed('code', 'rheum')\n",
    "cohort = cohort.join(rheum, 'patid', 'left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark3.7",
   "language": "python",
   "name": "pyspark37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
