{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rnshishir/deepmed/CPRD_Cut22/debug'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.insert(0, '/home/rnshishir/deepmed/CPRD_Cut22/')\n",
    "import shutil\n",
    "from utils.yaml_act import yaml_load\n",
    "from utils.arg_parse import arg_paser\n",
    "from CPRD.config.spark import spark_init, read_parquet\n",
    "import pyspark.sql.functions as F\n",
    "from CPRD.functions import tables, merge\n",
    "from CPRD.functions import merge\n",
    "from utils.utils import save_obj\n",
    "from CPRD.functions.MedicalDictionary import * \n",
    "from CPRD.functions.Prediction import * \n",
    "from CPRD.functions.cohort_select_causal import * \n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vocabCreate(CountsICD, num):\n",
    "    dic={}\n",
    "    dic['token2idx']={}\n",
    "    dic['idx2token']={}\n",
    "    dic['token2idx']['MASK']=4\n",
    "    dic['token2idx']['CLS']=3\n",
    "    dic['token2idx']['SEP']=2\n",
    "    dic['token2idx']['UNK']=1\n",
    "    dic['token2idx']['PAD']=0\n",
    "    dic['idx2token'][4]='MASK'\n",
    "    dic['idx2token'][3]='CLS'\n",
    "    dic['idx2token'][2]='SEP'\n",
    "    dic['idx2token'][1]='UNK'\n",
    "    dic['idx2token'][0]='PAD'\n",
    "    i=5\n",
    "    for x in CountsICD:\n",
    "        if CountsICD[x]>num:\n",
    "            dic['token2idx'][x]=i\n",
    "            dic['idx2token'][i]=x\n",
    "            i=i+1\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rnshishir/deepmed/CPRD_Cut22/utils/yaml_act.py:6: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  cfg = yaml.load(ymlfile)\n"
     ]
    }
   ],
   "source": [
    "args = dotdict({'params': '/home/rnshishir/deepmed/CPRD_Cut22/config/config.yaml'})\n",
    "params = yaml_load(args.params)\n",
    "spark_params = params['pyspark']\n",
    "spark = spark_init(spark_params)\n",
    "file = params['file_path']\n",
    "data_params = params['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'medication.main',\n",
       " 'pyspark': {'temp': '/home/rnshishir/sparkNewT',\n",
       "  'pyspark_env': '/home/rnshishir/anaconda3/envs/pyspark37/bin/python3.7'},\n",
       " 'file_path': {'clinical': '/home/workspace/datasets/cprd/cprd2021/*/*_Observation_*',\n",
       "  'patient': '/home/workspace/datasets/cprd/cprd2021/*/*_Patient_*',\n",
       "  'problem': '/home/workspace/datasets/cprd/cprd2021/*/*_Problem_*',\n",
       "  'therapy': '/home/workspace/datasets/cprd/cprd2021/*/*_DrugIssue_*',\n",
       "  'practice': '/home/workspace/datasets/cprd/cprd2021/*/*_Practice_*',\n",
       "  'consultation': '/home/workspace/datasets/cprd/cprd2021/*/*_Consultation_*',\n",
       "  'staff': '/home/workspace/datasets/cprd/cprd2021/*/*_Staff*',\n",
       "  'diagnosis_hes': '/home/workspace/datasets/cprd/cprd2021/linkage/20_095_Results/*/Aurum_linked/Final/hes_diagnosis_hosp_20_095_DM.txt',\n",
       "  'proc_hes': '/home/workspace/datasets/cprd/cprd2021/linkage/20_095_Results/*/Aurum_linked/Final/hes_procedures_epi_20_095_DM.txt',\n",
       "  'op_hes': '/home/workspace/datasets/cprd/cprd2021/linkage/20_095_Results/*/Aurum_linked/Final/hesop_clinical_20_095_DM.txt',\n",
       "  'death': '/home/workspace/datasets/cprd/cprd2021/linkage/20_095_Results/*/Aurum_linked/Final/death_patient_20_095_DM.txt',\n",
       "  'eligible': '/home/workspace/datasets/cprd/cprd2021/linkage_eligibility_Set21/linkage_eligibility*',\n",
       "  'med2read': '/home/workspace/datasets/cprd/cprd2021/202102_lookups/202102_EMISMedicalDictionary.txt',\n",
       "  'med2sno': '/home/workspace/datasets/cprd/cprd2021/202102_lookups/202102_EMISMedicalDictionary.txt',\n",
       "  'medicalDict': '/home/shared/shishir/AurumOut/Dicts/MedicalDictionary/CompiledDict/',\n",
       "  'uptodateDict': '/home/workspace/datasets/cprd/cprd2021/linkage/20_095_Results/Documentation/*/linkage_coverage_dictv.pkl',\n",
       "  'prod2bnf': '/home/workspace/datasets/cprd/cprd2021/202102_lookups/202102_EMISProductDictionary.txt',\n",
       "  'prod2bnf_vtm': '/home/shared/shishir/AurumOut/Dicts/meds_medcount_full.parquet',\n",
       "  'read2icd': '/home/workspace/datasets/cprd/cuts/02_cprd2015/3_Lookups/final_mapping.csv',\n",
       "  'sno2icd': '/home/shared/shishir/AurumOut/Dicts/snomed2icd.parquet',\n",
       "  'imd': '/home/workspace/datasets/cprd/cprd2021/linkage/20_095_Results/*/Aurum_linked/Final/patient_imd2015_20_095.txt',\n",
       "  'PhenoMaps': '/home/shared/shishir/AurumOut/Dicts/compiled_MD_30Jan2023'},\n",
       " 'params': {'bnf_mapping': True, 'time_range': [1985, 2022]},\n",
       " 'save_file': 'medication.parquet'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params have each of the individual files for data processing and other things like location of medical dict etc\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cohort selection\n",
    "### Association to study: effect of antihypertensives on ischaemic conditions\n",
    "\n",
    "-Cohort selection: age between 60 and 61 years in years between 2009 and 2010\n",
    "\n",
    "-take the first initiation of antihyp in this time to be baseline\n",
    "\n",
    "-take random baseline for those without any antihyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medical dict can give us both exposures and outcomes codes - e.g. diabetes as outcomes or antihyyp as exposurea\n",
    "md = MedicalDictionaryRiskPrediction(file, spark)\n",
    "temp = md.queryMedication(md.findItem('antihy'), merge= True)['merged']\n",
    "expcodes = {}\n",
    "expcodes['prodcode'] = temp['prodcode']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exposure selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CohortSoftCut from the causal cohort selection package has everything to select cohort and baseline\n",
    "# specifically the baseline for those WITH the exposure is date of exposure, and for those WITHOUT exp of interest is random sampling of baseline \n",
    "cohortSelector = CohortSoftCut(1,60, 61,  expcodes, False, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no mapping as you don't want to drop the prodcodes which are not mapped...\n",
    "# medications = retrieve_medications(file, spark, mapping='none', duration=(2009, 2010), demographics=cohort, practiceLink=True)\n",
    "# medications.write.parquet('/home/shared/shishir/AurumOut/rawDat/meds_nomapping_2009_2010_association_example.parquet')\n",
    "\n",
    "medications = read_parquet(spark.sqlContext, '/home/shared/shishir/AurumOut/rawDat/meds_nomapping_2009_2010_association_example.parquet')\n",
    "# medications.select('patid').dropDuplicates().count()  - 208603 patients have meds in the time period\n",
    "# medications.select('patid').count() - 11764962 number of records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline() function has 3 components:\n",
    "1) demo extract gets eligible patients between age 60 and 61 ^ defined above and years 2009 and 2010  \n",
    "2) extraction of the exposure of interest -  set  baseline as the date of the exposure  \n",
    "3) for those without exposure (i.e. control patients) , set up baseline as randomised baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = cohortSelector.pipeline(file, spark, duration=('2009-01-01', '2010-01-01'), randomNeg=True, sourceT=medications, sourceCol='prodcode', rollingTW=-1)\n",
    "cohort.write.parquet('/home/shared/shishir/AurumOut/rawDat/cohort_association_example.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225564"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = read_parquet(spark.sqlContext,'/home/shared/shishir/AurumOut/rawDat/cohort_association_example.parquet')\n",
    "cohort.count()\n",
    "# 259345 pats "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outcome selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = read_parquet(spark.sqlContext,'/home/shared/shishir/AurumOut/rawDat/cohort_association_example.parquet')\n",
    "\n",
    "necessaryColumns = ['patid',\n",
    " 'gender',\n",
    " 'dob',\n",
    " 'study_entry',\n",
    " 'startdate',\n",
    " 'enddate',\n",
    "  'exp_label']\n",
    "\n",
    "cohort = cohort.select(necessaryColumnsaryColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# label codes phenotyping from medical dict - ie maybe ischaemic conditions\n",
    "labelcodes  = md.queryDisease(md.findItem('ischaem'), merge= True)['merged']\n",
    "allIschaemiaCodes = labelcodes['medcode'] + labelcodes['ICD10'] +labelcodes['OPCS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label codes phenotyping from medical dict - ie maybe ischaemic conditions\n",
    "\n",
    "# split diags into icd and nonicd(medcode) and re-union as \"code\"\n",
    "allDiag = read_parquet(spark.sqlContext, '/home/shared/shishir/AurumOut/rawDat/diagGP_med2sno2icd_HESAPC_praclinkage_1985_2021.parquet')\n",
    "GPdiags = allDiag[allDiag.source=='CPRD']\n",
    "GPdiags = GPdiags.select(['patid' , 'eventdate', 'medcode']).withColumnRenamed('medcode', 'code')\n",
    "HESdiags = allDiag[allDiag.source=='HES']\n",
    "HESdiags = HESdiags.select(['patid' , 'eventdate', 'ICD']).withColumnRenamed('ICD', 'code')\n",
    "allDiag = GPdiags.union(HESdiags)\n",
    "\n",
    "# read death registry as death is an important data source for looking for outcome  \n",
    "death = tables.retrieve_death(dir=file['death'], spark=spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we use the risk prediction label capture class\n",
    "# basically with baseline we can capture 1) outcome, 2) time to outcome\n",
    "\n",
    "# the exclusion_codes is those we should exclude based on condition - i.e., exclude those with prior cancers \n",
    "# the duration is time we should consider the records in the outcome space (maybe from 2008 since earliest baseline is 2009 and end is 2020)\n",
    "# the follow_up_duration_month is number of months for the followup\n",
    "# the time_to_event_mark_default is mark as -1 if no event and lasts till end of follow-up\n",
    "# more information in package\n",
    "risk_pred_generator = OutcomePrediction(label_condition=allIschaemiaCodes, \n",
    "                                             exclusion_codes=None, \n",
    "                                             duration=(2008, 2020), \n",
    "                                             follow_up_duration_month=24,\n",
    "                                             time_to_event_mark_default=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# demographics is the cohort file with sutdy entry etc\n",
    "# source is the diag table\n",
    "# source_col is column that has the diags\n",
    "# exclusion_source is True if we want to exclude based on past diags\n",
    "\n",
    "# check_death is true if we are to check death \n",
    "# column_condition is column that has the diags or meds or whatever modality we are wanting to look for label\n",
    "# incidence is True if we are looking for incident lable\n",
    "# prevalent_conditions is if incidence is false, then what are some prevalent conditions we are allowing to look for (a subset of the labels)\n",
    "# more information in package\n",
    "\n",
    "\n",
    "\n",
    "risk_cohort = risk_pred_generator.pipeline( demographics=cohort, \n",
    "                                             source=allDiag, \n",
    "                                              exclusion_source=False,\n",
    "                                             check_death=True, \n",
    "                                             death=death,\n",
    "                                             column_condition='code', \n",
    "                                             incidence=True, \n",
    "                                             prevalent_conditions=None)\n",
    "\n",
    "\n",
    "\n",
    "risk_cohort. write.parquet('test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark3.7",
   "language": "python",
   "name": "pyspark37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
