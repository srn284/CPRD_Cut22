{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rnshishir/deepmed/CPRD_Cut22/debug'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.insert(0, '/home/rnshishir/deepmed/CPRD_Cut22/')\n",
    "import shutil\n",
    "from utils.yaml_act import yaml_load\n",
    "from utils.arg_parse import arg_paser\n",
    "from CPRD.config.spark import spark_init, read_parquet\n",
    "import pyspark.sql.functions as F\n",
    "from CPRD.functions import tables, merge\n",
    "from CPRD.functions import merge\n",
    "from utils.utils import save_obj\n",
    "from CPRD.functions.MedicalDictionary import * \n",
    "from CPRD.functions.Prediction import * \n",
    "from CPRD.functions.cohort_select_causal import * \n",
    "from CPRD.functions.predictor_extractor import *\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vocabCreate(CountsICD, num):\n",
    "    dic={}\n",
    "    dic['token2idx']={}\n",
    "    dic['idx2token']={}\n",
    "    dic['token2idx']['MASK']=4\n",
    "    dic['token2idx']['CLS']=3\n",
    "    dic['token2idx']['SEP']=2\n",
    "    dic['token2idx']['UNK']=1\n",
    "    dic['token2idx']['PAD']=0\n",
    "    dic['idx2token'][4]='MASK'\n",
    "    dic['idx2token'][3]='CLS'\n",
    "    dic['idx2token'][2]='SEP'\n",
    "    dic['idx2token'][1]='UNK'\n",
    "    dic['idx2token'][0]='PAD'\n",
    "    i=5\n",
    "    for x in CountsICD:\n",
    "        if CountsICD[x]>num:\n",
    "            dic['token2idx'][x]=i\n",
    "            dic['idx2token'][i]=x\n",
    "            i=i+1\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rnshishir/deepmed/CPRD_Cut22/utils/yaml_act.py:6: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  cfg = yaml.load(ymlfile)\n"
     ]
    }
   ],
   "source": [
    "args = dotdict({'params': '/home/rnshishir/deepmed/CPRD_Cut22/config/config.yaml'})\n",
    "params = yaml_load(args.params)\n",
    "spark_params = params['pyspark']\n",
    "spark = spark_init(spark_params)\n",
    "file = params['file_path']\n",
    "data_params = params['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'medication.main',\n",
       " 'pyspark': {'temp': '/home/rnshishir/sparkNewT',\n",
       "  'pyspark_env': '/home/rnshishir/anaconda3/envs/pyspark37/bin/python3.7'},\n",
       " 'file_path': {'clinical': '/home/workspace/datasets/cprd/cprd2021/*/*_Observation_*',\n",
       "  'patient': '/home/workspace/datasets/cprd/cprd2021/*/*_Patient_*',\n",
       "  'problem': '/home/workspace/datasets/cprd/cprd2021/*/*_Problem_*',\n",
       "  'therapy': '/home/workspace/datasets/cprd/cprd2021/*/*_DrugIssue_*',\n",
       "  'practice': '/home/workspace/datasets/cprd/cprd2021/*/*_Practice_*',\n",
       "  'consultation': '/home/workspace/datasets/cprd/cprd2021/*/*_Consultation_*',\n",
       "  'staff': '/home/workspace/datasets/cprd/cprd2021/*/*_Staff*',\n",
       "  'diagnosis_hes': '/home/workspace/datasets/cprd/cprd2021/linkage/20_095_Results/*/Aurum_linked/Final/hes_diagnosis_hosp_20_095_DM.txt',\n",
       "  'proc_hes': '/home/workspace/datasets/cprd/cprd2021/linkage/20_095_Results/*/Aurum_linked/Final/hes_procedures_epi_20_095_DM.txt',\n",
       "  'op_hes': '/home/workspace/datasets/cprd/cprd2021/linkage/20_095_Results/*/Aurum_linked/Final/hesop_clinical_20_095_DM.txt',\n",
       "  'death': '/home/workspace/datasets/cprd/cprd2021/linkage/20_095_Results/*/Aurum_linked/Final/death_patient_20_095_DM.txt',\n",
       "  'eligible': '/home/workspace/datasets/cprd/cprd2021/linkage_eligibility_Set21/linkage_eligibility*',\n",
       "  'med2read': '/home/workspace/datasets/cprd/cprd2021/202102_lookups/202102_EMISMedicalDictionary.txt',\n",
       "  'med2sno': '/home/workspace/datasets/cprd/cprd2021/202102_lookups/202102_EMISMedicalDictionary.txt',\n",
       "  'medicalDict': '/home/shared/shishir/AurumOut/Dicts/MedicalDictionary/CompiledDict/',\n",
       "  'uptodateDict': '/home/workspace/datasets/cprd/cprd2021/linkage/20_095_Results/Documentation/*/linkage_coverage_dictv.pkl',\n",
       "  'prod2bnf': '/home/workspace/datasets/cprd/cprd2021/202102_lookups/202102_EMISProductDictionary.txt',\n",
       "  'prod2bnf_vtm': '/home/shared/shishir/AurumOut/Dicts/meds_medcount_full.parquet',\n",
       "  'read2icd': '/home/workspace/datasets/cprd/cuts/02_cprd2015/3_Lookups/final_mapping.csv',\n",
       "  'sno2icd': '/home/shared/shishir/AurumOut/Dicts/snomed2icd.parquet',\n",
       "  'imd': '/home/workspace/datasets/cprd/cprd2021/linkage/20_095_Results/*/Aurum_linked/Final/patient_imd2015_20_095.txt',\n",
       "  'PhenoMaps': '/home/shared/shishir/AurumOut/Dicts/compiled_MD_30Jan2023'},\n",
       " 'params': {'bnf_mapping': True, 'time_range': [1985, 2022]},\n",
       " 'save_file': 'medication.parquet'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params have each of the individual files for data processing and other things like location of medical dict etc\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cohort selection\n",
    "### all eligible patients between 1985 and 2020 (not up to for covid reasons) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CohortSoftCut from the causal cohort selection package has everything to select cohort and baseline\n",
    "# specifically the baseline for those WITH the exposure is date of exposure, and for those WITHOUT exp of interest is random sampling of baseline \n",
    "cohortSelector = CohortSoftCut(1,18, 200,  None, False, False, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = cohortSelector.demoExtract(file, spark, duration=('1985-01-01', '2020-01-01'))\n",
    "\n",
    "cohort.write.parquet('/home/shared/shishir/AurumOut/rawDat/allelig_cohort_association_1985_2020.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26437981"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort = read_parquet(spark.sqlContext,'/home/shared/shishir/AurumOut/rawDat/allelig_cohort_association_1985_2020.parquet')\n",
    "cohort.count()\n",
    "# 259345 pats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13214057"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cohort = cohort .sample(0.5)\n",
    "# cohort.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = cohort.withColumn('enddate_real', F.least(F.col('exit_date'), F.col('enddate'))).drop('enddate_real').withColumnRenamed('enddate_real', 'enddate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = cohort.withColumn('label', F.lit(1))\n",
    "# this is just an include flag so we can include all elig patients (might be useful for future work hence putting it in now)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort=cohort.select([\n",
    "    \n",
    "    'patid',\n",
    "    'gender',\n",
    "    'region',\n",
    "    'startdate',\n",
    "    'enddate',\n",
    "    'label',\n",
    "    'dob'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDiag = read_parquet(spark.sqlContext, '/home/shared/shishir/AurumOut/rawDat/diagGP_med2sno2icd_HESAPC_praclinkage_1985_2021.parquet')\n",
    "meds = read_parquet(spark.sqlContext, '/home/shared/shishir/AurumOut/rawDat/medications_1985_2022_bnfvtm.parquet')\n",
    "\n",
    "allDiag = allDiag.select('patid','eventdate','ICD').withColumnRenamed('ICD','code')\n",
    "meds = meds.select('patid','eventdate','code')\n",
    "fullcodes = allDiag.union(meds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unique per year (i.e., delete duplicate rec in a given year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "extractorMLM = BEHRTextraction()\n",
    "dataout = extractorMLM.format_behrt(fullcodes, cohort, col_entry = 'enddate', unique_in_months=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataout.write.parquet('/home/shared/shishir/AurumOut/rawDat/MLM_for_pretraining_28M_1985_2020__unique_per6m_50pc_sample.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = read_parquet(spark.sqlContext,'/home/shared/shishir/AurumOut/rawDat/MLM_for_pretraining_28M_1985_2020__unique_per6m_50pc_sample.parquet')\n",
    "dat = dat.sample(.001)\n",
    "dat.write.parquet('/home/shared/shishir/AurumOut/rawDat/MLM_for_pretraining_28M_1985_2020__unique_per6m_50pc_sample___10kdebug.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### not implementing unique per year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractorMLM = BEHRTextraction()\n",
    "dataout = extractorMLM.format_behrt(fullcodes, cohort, col_entry = 'enddate', unique_in_months=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataout.write.parquet('/home/shared/shishir/AurumOut/rawDat/MLM_for_pretraining_28M_1985_2020.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = read_parquet(spark.sqlContext,'/home/shared/shishir/AurumOut/rawDat/MLM_for_pretraining_28M_1985_2020.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vocab creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullcountsdiag = pd.read_parquet('/home/shared/shishir/AurumOut/Dicts/diagGP_med2sno2icd_HESAPC_praclinkage_1985_2021__CodeCounts.parquet')\n",
    "fullcountsdiag =fullcountsdiag.rename(columns = {'count': 'val_counts','ICD':'target'})\n",
    "\n",
    "\n",
    "fullcountsmed = pd.read_parquet('/home/shared/shishir/AurumOut/Dicts/meds_medcount_full.parquet').rename(columns = {'medcounts': 'val_counts'})\n",
    "fullcountsmed = fullcountsmed[['target', 'val_counts']]\n",
    "\n",
    "fullcountsmed = fullcountsmed.groupby('target').agg(sum)\n",
    "fullcountsmed['target'] = fullcountsmed.index\n",
    "fullcountsmed  =fullcountsmed.reset_index(drop=True)\n",
    "fullcountsmed = fullcountsmed[['target', 'val_counts']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullcounttotal = pd.concat((fullcountsmed, fullcountsdiag))\n",
    "total =fullcounttotal.val_counts.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_to_keep=25000\n",
    "'code coverage:',(fullcounttotal[fullcounttotal.val_counts>num_to_keep].val_counts.sum()/total) , 'num codes kept:' , (len(fullcounttotal[fullcounttotal.val_counts>num_to_keep])/len(fullcounttotal))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_to_keep in [1000*xx for xx in [10,20,30,40,50,100,150]]:\n",
    "    print(num_to_keep, 'code coverage:',(fullcountsdiag[fullcountsdiag.val_counts>num_to_keep].val_counts.sum()/total) , 'num codes kept:' , (len(fullcountsdiag[fullcountsdiag.val_counts>num_to_keep])/len(fullcountsdiag))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for num_to_keep in [1000*xx for xx in [10,20,30,40,50,100,150]]:\n",
    "    print(num_to_keep, 'code coverage:',(fullcountsmed[fullcountsmed.val_counts>num_to_keep].val_counts.sum()/total) , 'num codes kept:' , (len(fullcountsmed[fullcountsmed.val_counts>num_to_keep])/len(fullcountsmed))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_to_keep in [1000*xx for xx in [1, 10,20,30,40,50,100,150]]:\n",
    "    print(num_to_keep, 'code coverage:',(fullcounttotal[fullcounttotal.val_counts>num_to_keep].val_counts.sum()/total) , 'num codes kept:' , (len(fullcounttotal[fullcounttotal.val_counts>num_to_keep])/len(fullcounttotal))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddcounts = {x:y for x, y in zip (codes.target.values, codes.val_counts.values) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabD = vocabCreate(ddcounts, 25000)\n",
    "save_obj(vocabD, 'tempdict')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark3.7",
   "language": "python",
   "name": "pyspark37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
